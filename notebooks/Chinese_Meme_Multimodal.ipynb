{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "363hvtIagHQS"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras_preprocessing"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6kKIsEzqIUF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGgf_pPylUAY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
        "import string\n",
        "import spacy\n",
        "import unicodedata\n",
        "import random\n",
        "import warnings\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Embedding, LSTM, multiply\n",
        "from keras.models import Model\n",
        "from keras import preprocessing, Input\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "from tensorflow.keras.models import load_model\n",
        "import itertools\n",
        "from PIL import Image, ImageFile\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten, Reshape, Permute\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Convolution1D, MaxPooling1D, Conv1D\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tensorflow.keras.layers import Add, BatchNormalization, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
        "\n",
        "# Verify GPU availability\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "np.random.seed(42)\n",
        "class color:  # Text style\n",
        "    PURPLE = '\\033[95m'\n",
        "    CYAN = '\\033[96m'\n",
        "    DARKCYAN = '\\033[36m'\n",
        "    BLUE = '\\033[94m'\n",
        "    GREEN = '\\033[92m'\n",
        "    YELLOW = '\\033[93m'\n",
        "    RED = '\\033[91m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'\n",
        "    END = '\\033[0m'\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Rest of your code...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XXGduR-lV82"
      },
      "outputs": [],
      "source": [
        "!pip install keras_preprocessing\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Embedding, LSTM, multiply\n",
        "from keras.models import Model\n",
        "from keras import preprocessing, Input\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "#Import from keras_preprocessing not from keras.preprocessing\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "from tensorflow.keras.models import load_model\n",
        "import itertools\n",
        "from PIL import Image, ImageFile\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Concatenate, Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten, Reshape, Permute\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Convolution1D,MaxPooling1D,Conv1D\n",
        "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from tensorflow.keras.layers import Add, BatchNormalization, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop,Adam,SGD,Nadam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def check_path(path):\n",
        "    \"\"\"\n",
        "    Check if a given path exists and determine if it's a file or directory.\n",
        "\n",
        "    Parameters:\n",
        "    path (str): The path to check.\n",
        "\n",
        "    Returns:\n",
        "    str: Message indicating whether the path exists, and if it's a file or directory.\n",
        "    \"\"\"\n",
        "    if os.path.exists(path):\n",
        "        if os.path.isdir(path):\n",
        "            return f\"The path '{path}' exists and is a directory.\"\n",
        "        elif os.path.isfile(path):\n",
        "            return f\"The path '{path}' exists and is a file.\"\n",
        "        else:\n",
        "            return f\"The path '{path}' exists.\"\n",
        "    else:\n",
        "        return f\"The path '{path}' does not exist.\"\n",
        "\n",
        "# Example usage\n",
        "path_to_check = 'content/drive/MyDrive/Research/Multimodal/Chinese/results/'\n",
        "result = check_path(path_to_check)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "okVeuzFEU25x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxhZHaVfgX5I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Try reading the CSV file with a different encoding\n",
        "df_labels = pd.read_csv('/content/drive/MyDrive/Research/Multimodal/Chinese/data/label_C.csv', encoding='latin1')\n",
        "df_text = pd.read_csv('/content/drive/MyDrive/Research/Multimodal/Chinese/data/C_text.csv', encoding='latin1')\n",
        "\n",
        "print(len(df_labels))\n",
        "print(len(df_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQXyvtx6gX2Y"
      },
      "outputs": [],
      "source": [
        "df_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoFyVTqwgXzf"
      },
      "outputs": [],
      "source": [
        "df_text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccv-0lpdgXwo"
      },
      "outputs": [],
      "source": [
        "for i in df_labels['sentiment category'].unique():\n",
        "  print(i,\"|->\", \"length:\", len(df_labels[df_labels['sentiment category']==i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdBH1175g6e6"
      },
      "outputs": [],
      "source": [
        "df_labels_copy = df_labels.copy()\n",
        "df_labels_copy.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPA9LUzMjyG3"
      },
      "outputs": [],
      "source": [
        "df_labels['sentiment category'] = df_labels['sentiment category'].str.extract('(\\d+)')\n",
        "\n",
        "df_labels['sentiment category'] = df_labels['sentiment category'].astype(int)\n",
        "\n",
        "df_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWd-Pal2j1RN"
      },
      "outputs": [],
      "source": [
        "df_labels = df_labels.iloc[:, :2]\n",
        "df_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9kaCfnxj5dY"
      },
      "outputs": [],
      "source": [
        "df_text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64YThuGyj_6F"
      },
      "outputs": [],
      "source": [
        "df_labels.insert(1, 'captions', df_text['text'])\n",
        "df_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xvFcykykCJD"
      },
      "outputs": [],
      "source": [
        "df_labels.rename(columns={'images_name': 'imagename'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmnA_FknkFRE"
      },
      "outputs": [],
      "source": [
        "df_labels.rename(columns={'sentiment category': 'label'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3jVjHQfkGcd"
      },
      "outputs": [],
      "source": [
        "df_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci98PQH5kJ1d"
      },
      "outputs": [],
      "source": [
        "# Replace \"Image_(\" with \"Image- (\"\n",
        "df_labels['imagename'] = df_labels['imagename'].str.replace('Image_(', 'Image- (')\n",
        "\n",
        "# Display the modified DataFrame\n",
        "df_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpUTRhlgkP6K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 0 --> positive\n",
        "# 1 --> negative\n",
        "\n",
        "label_mapping = {1: 0, 2: 0, 7: 0, 3: 1, 4: 1, 5: 1, 6: 1}\n",
        "\n",
        "# Apply the mapping to the \"label\" column\n",
        "df_labels['label'] = df_labels['label'].map(label_mapping)\n",
        "\n",
        "# Display the modified dataframe\n",
        "print(df_labels.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epJCvMjIlq2Q"
      },
      "source": [
        "## Train-Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvsCZl52lbIP"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = train_test_split(df_labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfzWMduQlbFg"
      },
      "outputs": [],
      "source": [
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(\"Test data shape:\", test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kla_IPL-mplg"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHv7Nm2flbC4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import string\n",
        "\n",
        "def text_cleaning_chinese(row):\n",
        "    # To remove HTML tags\n",
        "    text = BeautifulSoup(row, 'html.parser').get_text()\n",
        "    # This line is for removing URLs\n",
        "    text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text, flags=re.MULTILINE)\n",
        "    # Removing newline characters and specific characters\n",
        "    text = text.replace('\\n', '').replace('—', ' ').replace('。', ' ')\n",
        "    # Removing punctuation\n",
        "    text = ''.join([c for c in text if c not in string.punctuation])\n",
        "    # To remove special characters and extra spaces\n",
        "    pattern = r'^\\s*|\\s\\s*'\n",
        "    text = re.sub(pattern, ' ', text).strip()\n",
        "    # Convert into lower case (note: Chinese characters are unaffected by lowercasing)\n",
        "    text = text.lower()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlP3VP8jla_m"
      },
      "outputs": [],
      "source": [
        "# Assuming train_data and test_data are already defined and split from df_labels\n",
        "# Fill NaN values in 'captions' column with an empty string\n",
        "train_data['captions'] = train_data['captions'].fillna('')\n",
        "test_data['captions'] = test_data['captions'].fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlaI57S2mw55"
      },
      "outputs": [],
      "source": [
        "# Apply text_cleaning_chinese function\n",
        "train_data['cleaned'] = train_data['captions'].apply(text_cleaning_chinese)\n",
        "test_data['cleaned'] = test_data['captions'].apply(text_cleaning_chinese)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXonYrRQmyo2"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wL-4QSGm3BY"
      },
      "outputs": [],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SysXJLnbm4uf"
      },
      "source": [
        "## Image Spit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5LNwyytUm3Tf"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/drive/MyDrive/Research/Multimodal/Chinese/data/Cimages/Cimages/Cimages'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQH0UaHBnAw_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"Walks through dir_path returning its contents.\"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lH8hn63nWEX"
      },
      "outputs": [],
      "source": [
        "train_img_dir_path = '/content/drive/MyDrive/Research/Multimodal/Chinese/data/C_train-test/train_img'\n",
        "test_img_dir_path = '/content/drive/MyDrive/Research/Multimodal/Chinese/data/C_train-test/test_img'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjjO9gXwnBz3"
      },
      "outputs": [],
      "source": [
        "walk_through_dir(train_img_dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ELuz69mnBxP"
      },
      "outputs": [],
      "source": [
        "walk_through_dir(test_img_dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNnbVk4CnBu_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# # Example DataFrame\n",
        "# train_data = pd.DataFrame({\n",
        "#     'ImageName': ['Image_1.png', 'Image_2.jpg', 'Image_3.png'],\n",
        "#     'Caption': ['This is the first image', 'This is the second image', 'This is the third image']\n",
        "# })\n",
        "\n",
        "# Define the folder path\n",
        "# train_img_dir_path = \"/content/drive/MyDrive/Research/Multimodal/Chinese/data/C_train-test/train\"\n",
        "\n",
        "# List all files in the folder\n",
        "# all_files = os.listdir(train_img_dir_path)\n",
        "\n",
        "# Function to display an image with its caption\n",
        "def display_image_with_caption(image_name, caption):\n",
        "    image_path = os.path.join(train_img_dir_path, image_name)\n",
        "    if os.path.exists(image_path):\n",
        "        img = mpimg.imread(image_path)\n",
        "        plt.imshow(img)\n",
        "        plt.title(caption)\n",
        "        plt.axis('off')  # Hide the axes\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"File {image_path} does not exist.\")\n",
        "\n",
        "# Select the first image and its caption from the DataFrame\n",
        "if not train_data.empty:\n",
        "    first_row = train_data.iloc[0]\n",
        "    image_name = first_row['imagename']\n",
        "    caption = first_row['captions']\n",
        "\n",
        "    display_image_with_caption(image_name, caption)\n",
        "else:\n",
        "    print(\"The train_data DataFrame is empty.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DoCpF8knBr3"
      },
      "outputs": [],
      "source": [
        "# List all files in the folder\n",
        "# all_files = os.listdir(test_img_dir_path)\n",
        "\n",
        "# Function to display an image with its caption\n",
        "def display_image_with_caption(image_name, caption):\n",
        "    image_path = os.path.join(test_img_dir_path, image_name)\n",
        "    if os.path.exists(image_path):\n",
        "        img = mpimg.imread(image_path)\n",
        "        plt.imshow(img)\n",
        "        plt.title(caption)\n",
        "        plt.axis('off')  # Hide the axes\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"File {image_path} does not exist.\")\n",
        "\n",
        "# Select the first image and its caption from the DataFrame\n",
        "if not test_data.empty:\n",
        "    first_row = test_data.iloc[0]\n",
        "    image_name = first_row['imagename']\n",
        "    caption = first_row['captions']\n",
        "\n",
        "    display_image_with_caption(image_name, caption)\n",
        "else:\n",
        "    print(\"The test_data DataFrame is empty.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHSWKSXpoPi3"
      },
      "outputs": [],
      "source": [
        "# Function that returns image reading from the path\n",
        "def get_input(path):\n",
        "    # Loading image from given path\n",
        "    # and resizing it to 150*150*3 format\n",
        "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "    img = tf.keras.utils.load_img(path, target_size=(150,150))\n",
        "    return(img)\n",
        "\n",
        "# Takes in image and preprocess it\n",
        "def process_input(img):\n",
        "    # Converting image to array\n",
        "    img_data = tf.keras.utils.img_to_array(img)\n",
        "    # Adding one more dimension to array\n",
        "    img_data = np.expand_dims(img_data, axis=0)\n",
        "    #\n",
        "    img_data = preprocess_input(img_data)\n",
        "    return(img_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4TcVgs8oPdv"
      },
      "outputs": [],
      "source": [
        "# train_img_dir_path = '/content/drive/MyDrive/CM_MEMES-master/train_img'\n",
        "\n",
        "# Initialize the list to store image paths\n",
        "train_img_path = []\n",
        "# Append each image path to the list\n",
        "for root, dirs, files in os.walk(train_img_dir_path):\n",
        "    for file in files:\n",
        "        # Create the full path to the image file and append it to the list\n",
        "        if file.endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):  # add any other image formats if needed\n",
        "            train_img_path.append(os.path.join(root, file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCuK9aqsoPbR"
      },
      "outputs": [],
      "source": [
        "# test_img_dir_path = '/content/drive/MyDrive/CM_MEMES-master/test_img'\n",
        "\n",
        "# Initialize the list to store image paths\n",
        "test_img_path = []\n",
        "# Append each image path to the list\n",
        "for root, dirs, files in os.walk(test_img_dir_path):\n",
        "    for file in files:\n",
        "        # Create the full path to the image file and append it to the list\n",
        "        if file.endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):  # add any other image formats if needed\n",
        "            test_img_path.append(os.path.join(root, file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcmdSkMZoPYv"
      },
      "outputs": [],
      "source": [
        "# Create an array of training images\n",
        "train_images = []\n",
        "for i,m in enumerate(train_img_path):\n",
        "  input_img = get_input(m)\n",
        "  input_img = process_input(input_img)\n",
        "  train_images.append(input_img[0])\n",
        "  # print(i)\n",
        "\n",
        "# convert into numpy array\n",
        "train_image = np.array(train_images)\n",
        "print(train_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juolO0JAoPWP"
      },
      "outputs": [],
      "source": [
        "# Create an array of test images\n",
        "test_images = []\n",
        "for i,m in enumerate(test_img_path):\n",
        "  input_img = get_input(m)\n",
        "  input_img = process_input(input_img)\n",
        "  test_images.append(input_img[0])\n",
        "  # print(i)\n",
        "\n",
        "# convert into numpy array\n",
        "test_image = np.array(test_images)\n",
        "print(test_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWZ629Znobhf"
      },
      "source": [
        "## Summery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggTpMX2dodNC"
      },
      "outputs": [],
      "source": [
        "def data_summary(dataset):\n",
        "    documents = []\n",
        "    words = []\n",
        "    u_words = []\n",
        "    class_label= [k for k,v in dataset.label.value_counts().to_dict().items()]\n",
        "  # find word list\n",
        "    for label in class_label:\n",
        "        word_list = [word.strip().lower() for t in list(dataset[dataset.label==label].cleaned) for word in t.strip().split()]\n",
        "        counts = dict()\n",
        "        for word in word_list:\n",
        "                counts[word] = counts.get(word, 0)+1\n",
        "    # sort the dictionary of word list\n",
        "        ordered = sorted(counts.items(), key= lambda item: item[1],reverse = False)\n",
        "    # Documents per class\n",
        "        documents.append(len(list(dataset[dataset.label==label].cleaned)))\n",
        "    # Total Word per class\n",
        "        words.append(len(word_list))\n",
        "    # Unique words per class\n",
        "        u_words.append(len(np.unique(word_list)))\n",
        "\n",
        "        print(\"\\nClass Name : \",label)\n",
        "        print(\"Number of Comments:{}\".format(len(list(dataset[dataset.label==label].cleaned))))\n",
        "        print(\"Number of Words:{}\".format(len(word_list)))\n",
        "        print(\"Number of Unique Words:{}\".format(len(np.unique(word_list))))\n",
        "        print(\"Most Frequent Words:\\n\")\n",
        "        for k,v in ordered[:50]:\n",
        "              print(\"{}\\t{}\".format(k,v))\n",
        "\n",
        "    return documents,words,u_words,class_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9lVGyHfpASo"
      },
      "outputs": [],
      "source": [
        "documents,words,u_words,class_names = data_summary(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEUflcxypDlQ"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QYNrFlwpCGe"
      },
      "outputs": [],
      "source": [
        "def print_metrices(true,pred):\n",
        "    print(confusion_matrix(true,pred))\n",
        "    print(classification_report(true,pred,target_names=['0','1']))\n",
        "    print(\"Accuracy : \",accuracy_score(true,pred))\n",
        "    print(\"Precison : \",precision_score(true,pred, average = 'weighted'))\n",
        "    print(\"Recall : \",recall_score(true,pred,  average = 'weighted'))\n",
        "    print(\"F1 : \",f1_score(true,pred,  average = 'weighted'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bg6e4GXnpB_Y"
      },
      "outputs": [],
      "source": [
        "''' Callbacks'''\n",
        "keras.backend.clear_session()\n",
        "def callbacks_check(model_name):\n",
        "  accuracy_threshold = 0.98\n",
        "\n",
        "  class myCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy')>accuracy_threshold):\n",
        "          print(\"\\nReached %2.2f%% accuracy so we will stop trianing\" % (accuracy_threshold*100))\n",
        "          self.model.stop_training = True\n",
        "\n",
        "  acc_callback = myCallback()\n",
        "  # Saved the Best Model\n",
        "  filepath = models_path+f\"{model_name}.h5\"\n",
        "  checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=2, save_best_only=True,\n",
        "                                             save_weights_only=False, mode='max')\n",
        "  # callback list\n",
        "  callback_list = [acc_callback, checkpoint]\n",
        "\n",
        "  return callback_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uy5tmCypB8P"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import compute_class_weight\n",
        "class_weights = compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(train_data['label']),\n",
        "                                        y = train_data['label']\n",
        "                                    )\n",
        "class_weights = dict(zip(np.unique(train_data['label']), class_weights))\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txW9M2FapxIO"
      },
      "source": [
        "## Visual Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsW2xNzepB5o"
      },
      "outputs": [],
      "source": [
        "def visual_models(pretrained_model):\n",
        "  '''\n",
        "      Input: Pretrained Models weight\n",
        "  '''\n",
        "  base_model = pretrained_model\n",
        "  base_model.trainable = False\n",
        "  y = base_model.output\n",
        "  pool = GlobalAveragePooling2D()(y)\n",
        "  #flatten = Flatten()(pool)\n",
        "  output = Dense(3, activation='softmax')(pool)\n",
        "  # train model\n",
        "  img_model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "  return img_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8b3qThRp9ef"
      },
      "outputs": [],
      "source": [
        "xception = Xception(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "inception = InceptionV3(weights='imagenet', include_top=False,input_shape=(150, 150, 3)) #added inception\n",
        "vgg19 = VGG19(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "vgg16 = VGG16(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "resnet = ResNet50(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "densenet = DenseNet121(weights='imagenet', include_top=False,input_shape=(150, 150, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZkBKe2aqIeg"
      },
      "source": [
        "### xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-Zvnyu1p9bW"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "xcept_model = visual_models(xception)\n",
        "xcept_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                    optimizer=Adam(),\n",
        "                    metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcUwfGkQp9Yl",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "xcept_model.fit(x=train_image,\n",
        "              y=train_data['label'],\n",
        "              epochs=20,\n",
        "              batch_size =32,\n",
        "              validation_split = 0.1,\n",
        "              verbose = 1,\n",
        "              #class_weight = weight,\n",
        "              callbacks = callbacks_check('xception')\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvPyHAcpp9Vl"
      },
      "outputs": [],
      "source": [
        " # Prediction\n",
        "keras.backend.clear_session()\n",
        "model = load_model(models_path+\"xception.h5\")\n",
        "pred = model.predict(test_image)\n",
        "y_pred = np.argmax(pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6QOpOgUqClt"
      },
      "outputs": [],
      "source": [
        "y_true = test_data['label']\n",
        "print_metrices(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfvrhlSQqPgB"
      },
      "source": [
        "### Inception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttZF6aaUqCjO"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "inception_model = visual_models(inception)\n",
        "inception_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                    optimizer=Adam(),\n",
        "                    metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z34XsxmuqCgd",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "inception_model.fit(x=train_image,\n",
        "              y=train_data['label'],\n",
        "              epochs=20,\n",
        "              batch_size =32,\n",
        "              validation_split = 0.1,\n",
        "              verbose = 1,\n",
        "              callbacks = callbacks_check('inception')\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGmmvWCeqCdt"
      },
      "outputs": [],
      "source": [
        "#prediction\n",
        "keras.backend.clear_session()\n",
        "model = load_model(models_path+\"inception.h5\")\n",
        "pred = model.predict(test_image)\n",
        "y_pred = np.argmax(pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jFhvC-KqYGp"
      },
      "outputs": [],
      "source": [
        "y_true = test_data['label']\n",
        "print_metrices(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeafZsTmqafe"
      },
      "source": [
        "### vgg19"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwCjv25MqYDx"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "vgg19_model = visual_models(vgg19)\n",
        "vgg19_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                    optimizer=Adam(),\n",
        "                    metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgOBh-YVqYA-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "vgg19_model.fit(x=train_image,\n",
        "              y=train_data['label'],\n",
        "              epochs=20,\n",
        "              batch_size =32,\n",
        "              validation_split = 0.1,\n",
        "              verbose = 1,\n",
        "              callbacks = callbacks_check('vgg19')\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs0SibH2qfe3"
      },
      "outputs": [],
      "source": [
        " # Prediction\n",
        "keras.backend.clear_session()\n",
        "model = load_model(models_path+\"vgg19.h5\")\n",
        "pred = model.predict(test_image)\n",
        "y_pred = np.argmax(pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNk-OomFqfcV"
      },
      "outputs": [],
      "source": [
        "y_true = test_data['label']\n",
        "print_metrices(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuDPgBhAqu_-"
      },
      "source": [
        "### vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mWnQS5bqfZ5"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "vgg16_model = visual_models(vgg16)\n",
        "vgg16_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                    optimizer=RMSprop(),\n",
        "                    metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TblWAP4qfHe",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "vgg16_model.fit(x=train_image,\n",
        "              y=train_data['label'],\n",
        "              epochs=20,\n",
        "              batch_size =32,\n",
        "              validation_split = 0.1,\n",
        "              verbose = 1,\n",
        "              callbacks = callbacks_check('vgg16')\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgBzl82cqfEl"
      },
      "outputs": [],
      "source": [
        "# Prediction\n",
        "keras.backend.clear_session()\n",
        "model = load_model(models_path+\"vgg16.h5\")\n",
        "pred = model.predict(test_image)\n",
        "y_pred = np.argmax(pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wdnIZX6rXP4"
      },
      "outputs": [],
      "source": [
        "y_true = test_data['label']\n",
        "print_metrices(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETmEOrpgroKH"
      },
      "source": [
        "### resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYTTLTSlrXNW"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "resnet_model = visual_models(resnet)\n",
        "resnet_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                    optimizer=RMSprop(),\n",
        "                    metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_z_IOMcHrXGm",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "resnet_model.fit(x=train_image,\n",
        "              y=train_data['label'],\n",
        "              epochs=20,\n",
        "              batch_size =32,\n",
        "              validation_split = 0.1,\n",
        "              verbose = 1,\n",
        "              callbacks = callbacks_check('resnet-1')\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHsSJO0HrXEG"
      },
      "outputs": [],
      "source": [
        " # Prediction\n",
        "keras.backend.clear_session()\n",
        "model = load_model(models_path+\"resnet-1.h5\")\n",
        "pred = model.predict(test_image)\n",
        "y_pred = np.argmax(pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRT3KW2wrXBG"
      },
      "outputs": [],
      "source": [
        "y_true = test_data['label']\n",
        "print_metrices(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQt5dIyerzBG"
      },
      "source": [
        "### densenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmzRUsIwr1fv"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "densenet_model = visual_models(densenet)\n",
        "densenet_model.compile(loss='sparse_categorical_crossentropy',\n",
        "                    optimizer=Adam(),\n",
        "                    metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4oWM7n-r1bH",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "densenet_model.fit(x=train_image,\n",
        "              y=train_data['label'],\n",
        "              epochs=20,\n",
        "              batch_size =32,\n",
        "              validation_split = 0.1,\n",
        "              verbose = 1,\n",
        "              callbacks = callbacks_check('densenet')\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnpJawMnr1YW"
      },
      "outputs": [],
      "source": [
        " # Prediction\n",
        "keras.backend.clear_session()\n",
        "\n",
        "model = load_model(models_path+\"densenet.h5\")\n",
        "pred = model.predict(test_image)\n",
        "y_pred = np.argmax(pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUSZeLOHr1U-"
      },
      "outputs": [],
      "source": [
        "y_true = test_data['label']\n",
        "print_metrices(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cvMcBTmr-E3"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grWYXKsLr1SW"
      },
      "outputs": [],
      "source": [
        "visual_models = ['xception','inception','vgg16','resnet-1','densenet']\n",
        "visual_model_names = ['Xception','Inception','Vgg16','Resnet','Densenet']\n",
        "\n",
        "def visual_models_accuracy(saved_model):\n",
        "  my_dict = {}\n",
        "  # Prediction\n",
        "  model = load_model(models_path+f\"{saved_model}.h5\")\n",
        "  pred = model.predict(test_image)\n",
        "  y_pred = np.argmax(pred,axis=1)\n",
        "\n",
        "  y_true = test_data['label']\n",
        "\n",
        "  my_dict['Accuracy'] = accuracy_score(y_true, y_pred)*100\n",
        "  my_dict['Precision'] = precision_score(y_true, y_pred,average = 'weighted')*100\n",
        "  my_dict['Recall'] = recall_score(y_true, y_pred,average = 'weighted')*100\n",
        "  my_dict['F1 Score'] = f1_score(y_true, y_pred,average = 'weighted')*100\n",
        "  return my_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_path = '/content/drive/MyDrive/Research/Multimodal/Chinese/results'"
      ],
      "metadata": {
        "id": "XwJa-z2qZZnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAJsiOrcsBxv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "results_path = '/content/drive/MyDrive/Research/Multimodal/Chinese/results'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(results_path, exist_ok=True)\n",
        "\n",
        "accuracy = {f'{visual_model_names[i]}':visual_models_accuracy(model) for i,model in enumerate(visual_models)}\n",
        "# Save the performance parameter into json file\n",
        "with open(results_path+'visual_models_performance.json', 'w') as f:\n",
        "    json.dump(accuracy, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6G6oYAP3sBvW"
      },
      "outputs": [],
      "source": [
        "# Load the json file\n",
        "metrics = json.load(open(results_path+'visual_models_performance.json'))\n",
        "acc_list = []\n",
        "pr_list = []\n",
        "re_list = []\n",
        "f1_list = []\n",
        "for i in metrics.keys():\n",
        "  acc_list.append(round(metrics[i]['Accuracy'],2))\n",
        "  pr_list.append(round(metrics[i]['Precision'],2))\n",
        "  re_list.append(round(metrics[i]['Recall'],2))\n",
        "  f1_list.append(round(metrics[i]['F1 Score'],2))\n",
        "\n",
        "print (color.BOLD+f\"=======  Visual Models Performance on Test Data  =============\\n\"+color.END)\n",
        "# Create a dataframe\n",
        "performance_matrix = pd.DataFrame({'Accuracy':acc_list,'Precision':pr_list,\n",
        "                                   'Recall':re_list,'F1 Score':f1_list},\n",
        "                                  index =['Xception', 'Inception','Vgg16','Resnet','Densenet'])\n",
        "performance_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Model"
      ],
      "metadata": {
        "id": "UCwGh1VqBx57"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dm7uHNYrPbKD"
      },
      "outputs": [],
      "source": [
        "# Text Feature Extraction using TF-IDF\n",
        "cv = TfidfVectorizer(use_idf=True,tokenizer=lambda x: x.split())\n",
        "train_X = cv.fit_transform(train_data.captions)\n",
        "\n",
        "# Test data\n",
        "test_X = cv.transform(test_data.captions)\n",
        "\n",
        "print(\"\\nShape of TF-IDF Corpus =====>\",train_X.shape)\n",
        "print(\"\\nShape of TF-IDF Corpus =====>\",test_X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55KZZn4N3X0a"
      },
      "outputs": [],
      "source": [
        "lr_model = LogisticRegression(random_state = 123)\n",
        "dt_model = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
        "rf_model = RandomForestClassifier(n_estimators=10, criterion ='entropy', random_state = 0)\n",
        "mnb_model = MultinomialNB(alpha=0.05)\n",
        "svm_model = SVC(kernel = 'linear',probability=True,random_state = 0)\n",
        "model_names = ['Logistic Regression','Naive Bayes','SVM']\n",
        "ml_models = [lr_model,mnb_model,svm_model]\n",
        "\n",
        "def model_accuracy(model,X_train,X_test,y_train,y_test):\n",
        "  my_dict = {}\n",
        "  model.fit(X_train,y_train)\n",
        "  # Prediction\n",
        "  pred_y = model.predict(X_test)\n",
        "  my_dict['Accuracy'] = round(accuracy_score(y_test, pred_y),3)*100\n",
        "  my_dict['Precision'] = round(precision_score(y_test, pred_y,average='weighted'),3)*100\n",
        "  my_dict['Recall'] = round(recall_score(y_test, pred_y,average='weighted'),3)*100\n",
        "  my_dict['F1 Score'] = round(f1_score(y_test, pred_y,average='weighted'),3)*100\n",
        "  return my_dict\n",
        "\n",
        "# call model accuracy function and save the metrices into a dictionary\n",
        "accuracy = {f'{model_names[i]}':model_accuracy(model,train_X,test_X,train_data['label'],test_data['label']) for i,model in enumerate(ml_models)}\n",
        "# Save the performance parameter into json file\n",
        "with open(results_path +'ml_model_performance.json', 'w') as f:\n",
        "    json.dump(accuracy, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGOoXNJw335p"
      },
      "outputs": [],
      "source": [
        "# Load the json file\n",
        "accuracy = json.load(open(results_path +'ml_model_performance.json'))\n",
        "acc_list = []\n",
        "pr_list = []\n",
        "re_list = []\n",
        "f1_list = []\n",
        "for i in accuracy.keys():\n",
        "  acc_list.append(accuracy[i]['Accuracy'])\n",
        "  pr_list.append(accuracy[i]['Precision'])\n",
        "  re_list.append(accuracy[i]['Recall'])\n",
        "  f1_list.append(accuracy[i]['F1 Score'])\n",
        "\n",
        "# Create a dataframe\n",
        "performance_matrix = pd.DataFrame({'Accuracy':acc_list,'Precision':pr_list,\n",
        "                                   'Recall':re_list,'F1 Score':f1_list},\n",
        "                                  index =['LR','MNB','SVM'])\n",
        "performance_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9X5RxdIfTJd"
      },
      "outputs": [],
      "source": [
        "def text_tokenizer(train_data,test_data,vocabulary,max_len,sample_text_num):\n",
        "\n",
        "  tokenizer = Tokenizer(num_words = vocabulary ,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n-',\n",
        "                        split=' ', char_level=False, oov_token='<oov>', document_count=0)\n",
        "  tokenizer.fit_on_texts(train_data['captions'])\n",
        "  word_index = tokenizer.word_index\n",
        "  vocab_size = len(word_index)+1\n",
        "\n",
        "  # Training Sequences\n",
        "  train_sequences = tokenizer.texts_to_sequences(train_data['captions'])\n",
        "  train_pad_sequences =  keras.preprocessing.sequence.pad_sequences(train_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "\n",
        "  # valid Sequences\n",
        "  # valid_sequences = tokenizer.texts_to_sequences(valid_data['Captions'])\n",
        "  # valid_pad_sequences =  keras.preprocessing.sequence.pad_sequences(valid_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "\n",
        "\n",
        "  # Test Sequences\n",
        "  test_sequences = tokenizer.texts_to_sequences(test_data['captions'])\n",
        "  test_pad_sequences =  keras.preprocessing.sequence.pad_sequences(test_sequences, value=0.0, padding='post', maxlen= max_len)\n",
        "\n",
        "\n",
        "  print(color.BOLD+\"\\n\\t\\t\\t====== Encoded Sequences ======\"+color.END,\"\\n\")\n",
        "  print(train_data.captions[sample_text_num],\"\\n\",train_sequences[sample_text_num])\n",
        "  print(color.BOLD+\"\\n\\t\\t\\t====== Paded Sequences ======\\n\"+color.END,\"\\n\",train_pad_sequences[sample_text_num])\n",
        "\n",
        "  return train_pad_sequences,  test_pad_sequences, vocab_size, word_index\n",
        "\n",
        "  # return train_pad_sequences, valid_pad_sequences, test_pad_sequences, vocab_size, word_index\n",
        "\n",
        "\n",
        "vocabulary = 15000\n",
        "max_len = 60\n",
        "sample_text_num = 10\n",
        "\n",
        "## Call Tokenizer\n",
        "# train_pad_sequences, valid_pad_sequences, test_pad_sequences, vocab_size, word_index =  text_tokenizer(train_data,test_data,\n",
        "#                                                                       vocabulary,max_len,sample_text_num)\n",
        "\n",
        "train_pad_sequences,  test_pad_sequences, vocab_size, word_index =  text_tokenizer(train_data,test_data,\n",
        "                                                                      vocabulary,max_len,sample_text_num)\n",
        "\n",
        "print(\"Number of Train Sequences :\" ,train_pad_sequences.shape)\n",
        "# print(\"Number of Test Sequences :\" ,valid_pad_sequences.shape)\n",
        "print(\"Number of Test Sequences :\" ,test_pad_sequences.shape)\n",
        "print(\"Vocabulary Size: \",vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM Model"
      ],
      "metadata": {
        "id": "9PsY6xzUDdWH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJSqOgx740BW"
      },
      "outputs": [],
      "source": [
        "###### BiLSTM Model #######\n",
        "bi_text_inputs = Input(shape=(max_len,))\n",
        "bi_embedding_layer = Embedding(vocab_size,64)(bi_text_inputs)\n",
        "LSTM_Layer_1 = Bidirectional(LSTM(32))(bi_embedding_layer)\n",
        "bi_dense_layer_1 = Dense(3, activation='softmax')(LSTM_Layer_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model = Model(inputs=bi_text_inputs, outputs=bi_dense_layer_1)"
      ],
      "metadata": {
        "id": "RrF4sn4859jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTihfRdy441e",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "bilstm_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "bilstm_model.fit(train_pad_sequences,\n",
        "    train_data['label'],\n",
        "    epochs= 20,\n",
        "    batch_size =32,\n",
        "    validation_split = 0.1,\n",
        "    verbose =1,\n",
        "    callbacks = callbacks_check('lstm'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6Czndo946Z-"
      },
      "outputs": [],
      "source": [
        " # Prediction\n",
        "model = load_model(models_path+\"lstm.h5\")\n",
        "pred = model.predict(test_pad_sequences)\n",
        "y_pred = np.argmax(pred,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EktRc0vM48U2"
      },
      "outputs": [],
      "source": [
        "y_true = test_data['label']\n",
        "print_metrices(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN"
      ],
      "metadata": {
        "id": "r0H-UvuCDksW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSJYY-pe5PjI"
      },
      "outputs": [],
      "source": [
        "### CNN\n",
        "cnn_text_inputs = Input(shape=(max_len,))\n",
        "cnn_embedding_layer = Embedding(vocab_size,64)(cnn_text_inputs)\n",
        "cnn_conv1 = Conv1D(64,2,activation='relu')(cnn_embedding_layer)\n",
        "cnn_conv2 = Conv1D(32,2,activation='relu')(cnn_conv1)\n",
        "cnn_pool1 = MaxPooling1D(2)(cnn_conv2)\n",
        "\n",
        "cnn_flat = Flatten()(cnn_pool1)\n",
        "cnn_dense_layer_1 = Dense(3, activation='softmax')(cnn_flat)\n",
        "cnn_model = Model(inputs=cnn_text_inputs, outputs=cnn_dense_layer_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1KTnxX55QPG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "cnn_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "cnn_model.fit(train_pad_sequences,\n",
        "    train_data['label'],\n",
        "    epochs=20,\n",
        "    batch_size =32,\n",
        "    validation_split = 0.1,\n",
        "    verbose =1,\n",
        "    callbacks = callbacks_check('cnn'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYNktCRp5jlt"
      },
      "outputs": [],
      "source": [
        " # Prediction\n",
        "model = load_model(models_path+\"cnn.h5\")\n",
        "pred = model.predict(test_pad_sequences)\n",
        "y_pred = np.argmax(pred,axis=1)\n",
        "y_true = test_data['label']\n",
        "print_metrices(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM-CNN Model"
      ],
      "metadata": {
        "id": "wB9ajAKDDpa9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdXjd4zO5qSj"
      },
      "outputs": [],
      "source": [
        "##### LSTM-CNN Model ####\n",
        "lc_text_inputs = Input(shape=(max_len,))\n",
        "lc_embedding_layer = Embedding(vocab_size,64)(lc_text_inputs)\n",
        "LSTM_Layer = Bidirectional(LSTM(32,return_sequences=True))(lc_embedding_layer)\n",
        "lc_conv1 = Conv1D(32,2,activation='relu')(LSTM_Layer)\n",
        "lc_pool1 = MaxPooling1D(2)(lc_conv1)\n",
        "lc_flat = Flatten()(lc_pool1)\n",
        "lc_dense_layer_1 = Dense(3, activation='softmax')(lc_flat)\n",
        "cnn_lstm_model = Model(inputs=lc_text_inputs, outputs=lc_dense_layer_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iHmE65s5rtL",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "cnn_lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "cnn_lstm_model.fit(train_pad_sequences,\n",
        "    train_data['label'],\n",
        "    epochs=20,\n",
        "    batch_size =32,\n",
        "    validation_split = 0.1,\n",
        "    verbose =1,\n",
        "    callbacks = callbacks_check('lstm-cnn'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y66_vsLe5tK7"
      },
      "outputs": [],
      "source": [
        " # Prediction\n",
        "model = load_model(models_path+\"lstm-cnn.h5\")\n",
        "pred = model.predict(test_pad_sequences)\n",
        "y_pred = np.argmax(pred,axis=1)\n",
        "y_true = test_data['label']\n",
        "print_metrices(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe-AgXvaUlZQ"
      },
      "source": [
        "## **Multimodal (Late Fusion)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhfkHfrJUh0j"
      },
      "outputs": [],
      "source": [
        "def visual_models():\n",
        "  '''\n",
        "      Input: Pretrained Models weight\n",
        "  '''\n",
        "  ## ResNet50\n",
        "  resnet = ResNet50(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "  resnet_model = resnet\n",
        "  resnet_model.trainable = False\n",
        "  resnet_y = resnet_model.output\n",
        "  resnet_pool = GlobalAveragePooling2D()(resnet_y)\n",
        "  resnet_output = Dense(2, activation='softmax')(resnet_pool)\n",
        "  # this is the model we will train\n",
        "  resnet_img_model = Model(inputs=resnet_model.input, outputs=resnet_output)\n",
        "\n",
        "  ## VGG16\n",
        "  vgg16 = VGG16(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "  vgg16_model = vgg16\n",
        "  vgg16_model.trainable = False\n",
        "  vgg16_y = vgg16_model.output\n",
        "  vgg16_pool = GlobalAveragePooling2D()(vgg16_y)\n",
        "  vgg16_output = Dense(2, activation='softmax')(vgg16_pool)\n",
        "  # this is the model we will train\n",
        "  vgg16_img_model = Model(inputs=vgg16_model.input, outputs=vgg16_output)\n",
        "\n",
        "  ## DenseNet\n",
        "  densenet = DenseNet121(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "  densenet_model = densenet\n",
        "  densenet_model.trainable = False\n",
        "  densenet_y = densenet_model.output\n",
        "  densenet_pool = GlobalAveragePooling2D()(densenet_y)\n",
        "  densenet_output = Dense(2, activation='softmax')(densenet_pool)\n",
        "  # this is the model we will train\n",
        "  densenet_img_model = Model(inputs=densenet_model.input, outputs=densenet_output)\n",
        "\n",
        "  ## Inception V3\n",
        "  inception = InceptionV3(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "  inception_model = inception\n",
        "  inception_model.trainable = False\n",
        "  inception_y = inception_model.output\n",
        "  inception_pool = GlobalAveragePooling2D()(inception_y)\n",
        "  inception_output = Dense(2, activation='softmax')(inception_pool)\n",
        "  # this is the model we will train\n",
        "  inception_img_model = Model(inputs=inception_model.input, outputs=inception_output)\n",
        "\n",
        "  image_models = [resnet_img_model,densenet_img_model,vgg16_img_model,inception_model]\n",
        "\n",
        "  return image_models\n",
        "\n",
        "\n",
        "def textual_models():\n",
        "\n",
        "  ###### BiLSTM Model #######\n",
        "  bi_text_inputs = Input(shape=(max_len,))\n",
        "  bi_embedding_layer = Embedding(vocab_size,64)(bi_text_inputs)\n",
        "  LSTM_Layer_1 = Bidirectional(LSTM(32))(bi_embedding_layer)\n",
        "  bi_dense_layer_1 = Dense(3, activation='softmax')(LSTM_Layer_1)\n",
        "  bilstm_model = Model(inputs=bi_text_inputs, outputs=bi_dense_layer_1)\n",
        "\n",
        "\n",
        "  ### CNN\n",
        "  cnn_text_inputs = Input(shape=(max_len,))\n",
        "  cnn_embedding_layer = Embedding(vocab_size,64)(cnn_text_inputs)\n",
        "  cnn_conv1 = Conv1D(64,2,activation='relu')(cnn_embedding_layer)\n",
        "  cnn_conv2 = Conv1D(32,2,activation='relu')(cnn_conv1)\n",
        "  cnn_pool1 = MaxPooling1D(2)(cnn_conv2)\n",
        "\n",
        "  cnn_flat = Flatten()(cnn_pool1)\n",
        "  cnn_dense_layer_1 = Dense(3, activation='softmax')(cnn_flat)\n",
        "  cnn_model = Model(inputs=cnn_text_inputs, outputs=cnn_dense_layer_1)\n",
        "\n",
        "\n",
        "\n",
        "  ##### LSTM-CNN Model ####\n",
        "  lc_text_inputs = Input(shape=(max_len,))\n",
        "  lc_embedding_layer = Embedding(vocab_size,64)(lc_text_inputs)\n",
        "  LSTM_Layer = Bidirectional(LSTM(32,return_sequences=True))(lc_embedding_layer)\n",
        "  lc_conv1 = Conv1D(32,2,activation='relu')(LSTM_Layer)\n",
        "  lc_pool1 = MaxPooling1D(2)(lc_conv1)\n",
        "  lc_flat = Flatten()(lc_pool1)\n",
        "  lc_dense_layer_1 = Dense(3, activation='softmax')(lc_flat)\n",
        "  cnn_lstm_model = Model(inputs=lc_text_inputs, outputs=lc_dense_layer_1)\n",
        "\n",
        "  ############\n",
        "  dl_textual_models = [bilstm_model,cnn_model,cnn_lstm_model]\n",
        "\n",
        "  return dl_textual_models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Resnet**"
      ],
      "metadata": {
        "id": "A7glYetkAR3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ovDaiEMV3Sm",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "for tm,textual_model in enumerate(dl_textual_models_lsit):\n",
        "  # Concatenating the output of 2 classifiers\n",
        "  con_layer = keras.layers.concatenate([visual_models_lsit[0].output, textual_model.output])\n",
        "  # Provide a unique name for this Dense layer using tm in the name\n",
        "  final_dense = Dense(4, activation=\"relu\", name=f\"final_dense_{tm}\")(con_layer)\n",
        "  #dropout = Dropout(0.1)(final_dense)\n",
        "  # Provide a unique name for the output layer using tm in the name\n",
        "  out = Dense(2,activation='softmax', name=f\"output_layer_{tm}\")(final_dense)\n",
        "  com_model = Model(inputs = [visual_models_lsit[0].input, textual_model.input], outputs=out)\n",
        "\n",
        "  com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics = [\"accuracy\"])\n",
        "\n",
        "\n",
        "  print(\"\\nModel Name:=====>\\n\",visual_model_name[0]+'_'+dl_textual_model_name[tm]+'_late')\n",
        "\n",
        "  com_model.fit([train_image,train_pad_sequences],\n",
        "                      train_data['label'],\n",
        "                      validation_split = 0.1,\n",
        "                      epochs=20,\n",
        "                      batch_size=32,\n",
        "                      callbacks = callbacks_check(visual_model_name[0]+'_'+dl_textual_model_name[tm]+'_late')\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DenseNet**"
      ],
      "metadata": {
        "id": "wornV-b_AV71"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWWs-E2XFFEA",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "for tm,textual_model in enumerate(dl_textual_models_lsit):\n",
        "  # Concatenating the output of 2 classifiers\n",
        "  con_layer = keras.layers.concatenate([visual_models_lsit[1].output, textual_model.output])\n",
        "  # Provide a unique name for this Dense layer using tm in the name\n",
        "  final_dense = Dense(4, activation=\"relu\", name=f\"final_dense_{tm}\")(con_layer)\n",
        "  #dropout = Dropout(0.1)(final_dense)\n",
        "  # Provide a unique name for the output layer using tm in the name\n",
        "  out = Dense(2,activation='softmax', name=f\"output_layer_{tm}\")(final_dense)\n",
        "  com_model = Model(inputs = [visual_models_lsit[1].input, textual_model.input], outputs=out)\n",
        "\n",
        "  com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics = [\"accuracy\"])\n",
        "\n",
        "\n",
        "  print(\"\\nModel Name:=====>\\n\",visual_model_name[1]+'_'+dl_textual_model_name[tm]+'_late')\n",
        "\n",
        "  com_model.fit([train_image,train_pad_sequences],\n",
        "                      train_data['label'],\n",
        "                      validation_split = 0.1,\n",
        "                      epochs=20,\n",
        "                      batch_size=32,\n",
        "                      callbacks = callbacks_check(visual_model_name[1]+'_'+dl_textual_model_name[tm]+'_late')\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vgg16**"
      ],
      "metadata": {
        "id": "0qyIoIn5Abg8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gVxj6BJ6fB-",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "for tm,textual_model in enumerate(dl_textual_models_lsit):\n",
        "  # Concatenating the output of 2 classifiers\n",
        "  con_layer = keras.layers.concatenate([visual_models_lsit[2].output, textual_model.output])\n",
        "  # Provide a unique name for this Dense layer using tm in the name\n",
        "  final_dense = Dense(4, activation=\"relu\", name=f\"final_dense_{tm}\")(con_layer)\n",
        "  #dropout = Dropout(0.1)(final_dense)\n",
        "  # Provide a unique name for the output layer using tm in the name\n",
        "  out = Dense(2,activation='softmax', name=f\"output_layer_{tm}\")(final_dense)\n",
        "  com_model = Model(inputs = [visual_models_lsit[2].input, textual_model.input], outputs=out)\n",
        "\n",
        "  com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics = [\"accuracy\"])\n",
        "\n",
        "\n",
        "  print(\"\\nModel Name:=====>\\n\",visual_model_name[2]+'_'+dl_textual_model_name[tm]+'_late')\n",
        "\n",
        "  com_model.fit([train_image,train_pad_sequences],\n",
        "                      train_data['label'],\n",
        "                      validation_split = 0.1,\n",
        "                      epochs=20,\n",
        "                      batch_size=32,\n",
        "                      callbacks = callbacks_check(visual_model_name[2]+'_'+dl_textual_model_name[tm]+'_late')\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Inception v3**"
      ],
      "metadata": {
        "id": "v4YUx94yAhOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for tm,textual_model in enumerate(dl_textual_models_lsit):\n",
        "  # Concatenating the output of 2 classifiers\n",
        "  # Reshape or flatten the output of one or both models to make them compatible for concatenation\n",
        "  visual_output = keras.layers.Flatten()(visual_models_lsit[3].output) # Flatten the visual model output\n",
        "  con_layer = keras.layers.concatenate([visual_output, textual_model.output])\n",
        "  # Provide a unique name for this Dense layer using tm in the name\n",
        "  final_dense = Dense(4, activation=\"relu\", name=f\"final_dense_{tm}\")(con_layer)\n",
        "  #dropout = Dropout(0.1)(final_dense)\n",
        "  # Provide a unique name for the output layer using tm in the name\n",
        "  out = Dense(2,activation='softmax', name=f\"output_layer_{tm}\")(final_dense)\n",
        "  com_model = Model(inputs = [visual_models_lsit[3].input, textual_model.input], outputs=out)\n",
        "\n",
        "  com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics = [\"accuracy\"])\n",
        "\n",
        "\n",
        "  print(\"\\nModel Name:=====>\\n\",visual_model_name[3]+'_'+dl_textual_model_name[tm]+'_late')\n",
        "\n",
        "  com_model.fit([train_image,train_pad_sequences],\n",
        "                      train_data['label'],\n",
        "                      validation_split = 0.1,\n",
        "                      epochs=20,\n",
        "                      batch_size=32,\n",
        "                      callbacks = callbacks_check(visual_model_name[3]+'_'+dl_textual_model_name[tm]+'_late')\n",
        "            )"
      ],
      "metadata": {
        "id": "EHI7Iy_0DlEt",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDKUzq3CgmQK"
      },
      "outputs": [],
      "source": [
        "for vm in visual_model_name:\n",
        "  for tm in dl_textual_model_name:\n",
        "    print('Model name ===> ',vm+'_'+tm)\n",
        "    model = load_model(models_path+ vm+'_'+tm+'_late'+\".h5\")\n",
        "    pred = model.predict([test_image,test_pad_sequences])\n",
        "    y_pred = np.argmax(pred,axis=1)\n",
        "    print_metrices(test_data['label'], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_s99ubsFi3X"
      },
      "source": [
        "## **Multimodal (Early Fusion)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-yvMgCvFiK2"
      },
      "outputs": [],
      "source": [
        "def visual_models():\n",
        "  '''\n",
        "      Input: Pretrained Models weight\n",
        "  '''\n",
        "  ## ResNet50\n",
        "  resnet = ResNet50(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "  resnet_model = resnet\n",
        "  resnet_model.trainable = False\n",
        "  resnet_y = resnet_model.output\n",
        "  resnet_pool = GlobalAveragePooling2D()(resnet_y)\n",
        "  resnet_output = Dense(10, activation='relu')(resnet_pool)\n",
        "  # this is the model we will train\n",
        "  resnet_img_model = Model(inputs=resnet_model.input, outputs=resnet_output)\n",
        "\n",
        "  ## Vgg16\n",
        "  vgg16 = VGG16(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "  vgg16_model = vgg16\n",
        "  vgg16_model.trainable = False\n",
        "  vgg16_y = vgg16_model.output\n",
        "  vgg16_pool = GlobalAveragePooling2D()(vgg16_y)\n",
        "  vgg16_output = Dense(10, activation='relu')(vgg16_pool)\n",
        "  # this is the model we will\n",
        "  vgg16_img_model = Model(inputs=vgg16_model.input, outputs=vgg16_output)\n",
        "\n",
        "  ## DenseNet\n",
        "  densenet = DenseNet121(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "  densenet_model = densenet\n",
        "  densenet_model.trainable = False\n",
        "  densenet_y = densenet_model.output\n",
        "  densenet_pool = GlobalAveragePooling2D()(densenet_y)\n",
        "  densenet_output = Dense(10, activation='relu')(densenet_pool)\n",
        "  # this is the model we will train\n",
        "  densenet_img_model = Model(inputs=densenet_model.input, outputs=densenet_output)\n",
        "\n",
        "  ## Inception v3\n",
        "  inception = InceptionV3(weights='imagenet', include_top=False,input_shape=(150, 150, 3))\n",
        "  inception_model = inception\n",
        "  inception_model.trainable = False\n",
        "  inception_y = inception_model.output\n",
        "  inception_pool = GlobalAveragePooling2D()(inception_y)\n",
        "  inception_output = Dense(10, activation='relu')(inception_pool)\n",
        "  # this is the model we will train\n",
        "  inception_img_model = Model(inputs=inception_model.input, outputs=inception_output)\n",
        "\n",
        "  #image_models = [inception_model, resnet_img_model,densenet_img_model, vgg16_img_model]\n",
        "  image_models = [resnet_img_model,densenet_img_model, vgg16_img_model,inception_model]\n",
        "\n",
        "  return image_models\n",
        "\n",
        "\n",
        "def textual_models():\n",
        "\n",
        "  ###### BiLSTM Model #######\n",
        "  bi_text_inputs = Input(shape=(max_len,))\n",
        "  bi_embedding_layer = Embedding(vocab_size,64)(bi_text_inputs)\n",
        "  LSTM_Layer_1 = Bidirectional(LSTM(32))(bi_embedding_layer)\n",
        "  bi_dense_layer_1 = Dense(10, activation='relu')(LSTM_Layer_1)\n",
        "  bilstm_model = Model(inputs=bi_text_inputs, outputs=bi_dense_layer_1)\n",
        "\n",
        "\n",
        "  ### CNN\n",
        "  cnn_text_inputs = Input(shape=(max_len,))\n",
        "  cnn_embedding_layer = Embedding(vocab_size,64)(cnn_text_inputs)\n",
        "  cnn_conv1 = Conv1D(64,2,activation='relu')(cnn_embedding_layer)\n",
        "  cnn_conv2 = Conv1D(32,2,activation='relu')(cnn_conv1)\n",
        "  cnn_pool1 = MaxPooling1D(2)(cnn_conv2)\n",
        "\n",
        "  cnn_flat = Flatten()(cnn_pool1)\n",
        "  cnn_dense_layer_1 = Dense(10, activation='relu')(cnn_flat)\n",
        "  cnn_model = Model(inputs=cnn_text_inputs, outputs=cnn_dense_layer_1)\n",
        "\n",
        "\n",
        "\n",
        "  ##### LSTM-CNN Model ####\n",
        "  lc_text_inputs = Input(shape=(max_len,))\n",
        "  lc_embedding_layer = Embedding(vocab_size,64)(lc_text_inputs)\n",
        "  LSTM_Layer = Bidirectional(LSTM(32,return_sequences=True))(lc_embedding_layer)\n",
        "  lc_conv1 = Conv1D(32,2,activation='relu')(LSTM_Layer)\n",
        "  lc_pool1 = MaxPooling1D(2)(lc_conv1)\n",
        "  lc_flat = Flatten()(lc_pool1)\n",
        "  lc_dense_layer_1 = Dense(10, activation='relu')(lc_flat)\n",
        "  cnn_lstm_model = Model(inputs=lc_text_inputs, outputs=lc_dense_layer_1)\n",
        "\n",
        "  ############\n",
        "  dl_textual_models = [bilstm_model,cnn_model,cnn_lstm_model]\n",
        "\n",
        "  return dl_textual_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpyZJCM0F56m"
      },
      "outputs": [],
      "source": [
        "#visual_model_name = ['Inception', 'ResNet','DenseNet','Vgg16']\n",
        "visual_model_name = ['ResNet','DenseNet','Vgg16','Inception']\n",
        "visual_models_lsit = visual_models()\n",
        "\n",
        "dl_textual_model_name = ['LSTM','CNN','LSTM+CNN']\n",
        "dl_textual_models_lsit = textual_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npshGOkeQCWE"
      },
      "outputs": [],
      "source": [
        "visual_models_lsit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_path = '/content/drive/MyDrive/Research/Multimodal/Chinese/'"
      ],
      "metadata": {
        "id": "11p9g2woauU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for vm,visual_model in enumerate(visual_models_lsit):\n",
        "#   for tm,textual_model in enumerate(dl_textual_models_lsit):\n",
        "#     # Concatenating the output of 2 classifiers\n",
        "#     # Flatten the visual model output to make it 2D\n",
        "#     visual_flat = Flatten()(visual_model.output)\n",
        "#     con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "\n",
        "#     #final_dense = Dense(10, activation=\"relu\")(con_layer)\n",
        "#     #dropout = Dropout(0.01)(final_dense)\n",
        "#     out = Dense(2,activation='softmax')(con_layer)\n",
        "#     com_model = Model(inputs = [visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "#     com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics = [\"accuracy\"])\n",
        "\n",
        "\n",
        "#     print(\"\\nModel Name:=====>\\n\",visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "#     com_model.fit([train_image,train_pad_sequences],\n",
        "#                       train_data['label'],\n",
        "#                       validation_split = 0.1,\n",
        "#                       epochs=20,\n",
        "#                       batch_size=32,\n",
        "#                       callbacks = callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm])\n",
        "#             )"
      ],
      "metadata": {
        "id": "7Sdx3hxsF5_H",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet + LSTM\n",
        "vm = 0\n",
        "tm = 0\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DKzE7FWsRaK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'ResNet'\n",
        "tm = 'LSTM'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "j6tXHOJDfXKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet + CNN\n",
        "vm = 0\n",
        "tm = 1\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iF-ENKodRaFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'ResNet'\n",
        "tm = 'CNN'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "WITq5LavfbeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet + LSTM+CNN\n",
        "vm = 0\n",
        "tm = 2\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gGlJzlXDRaBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'ResNet'\n",
        "tm = 'LSTM+CNN'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "OQuhwhT4fe5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DenseNet + LSTM\n",
        "vm = 1\n",
        "tm = 0\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1Mgr3b5ARZ-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'DenseNet'\n",
        "tm = 'LSTM'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "mwzu8RkIfhwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DenseNet + CNN\n",
        "vm = 1\n",
        "tm = 1\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "id": "mEMsHfG4RZ6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'DenseNet'\n",
        "tm = 'CNN'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "ekHlt4qEgcVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DenseNet + LSTM+CNN\n",
        "vm = 1\n",
        "tm = 2\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "id": "jvjk91THRZ38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'DenseNet'\n",
        "tm = 'LSTM+CNN'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "J9PEUOaYgdwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vgg16 + LSTM\n",
        "vm = 2\n",
        "tm = 0\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "id": "2jRSYdWRRZ0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'Vgg16'\n",
        "tm = 'LSTM'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "ZQQq0KLsgfCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vgg16 + CNN\n",
        "vm = 2\n",
        "tm = 1\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "id": "hL0YHLl6RZxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'Vgg16'\n",
        "tm = 'CNN'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "GEqKMXmKggcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vgg16 + LSTM+CNN\n",
        "vm = 2\n",
        "tm = 2\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "id": "blSYAJiQRZt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'Vgg16'\n",
        "tm = 'LSTM+CNN'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "m9H84VuyghlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inception + LSTM\n",
        "vm = 3\n",
        "tm = 0\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "id": "MZ6tT2O7RZqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'Inception'\n",
        "tm = 'LSTM'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "mH1uVTrxgjmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inception + CNN\n",
        "vm = 3\n",
        "tm = 1\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "id": "wTLr0eleRZnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'Inception'\n",
        "tm = 'CNN'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "MuLauPi7gkm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inception + LSTM+CNN\n",
        "vm = 3\n",
        "tm = 2\n",
        "visual_model = visual_models_lsit[vm]\n",
        "textual_model = dl_textual_models_lsit[tm]\n",
        "\n",
        "visual_flat = Flatten()(visual_model.output)\n",
        "con_layer = keras.layers.concatenate([visual_flat, textual_model.output])\n",
        "out = Dense(2, activation='softmax')(con_layer)\n",
        "com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"\\nModel Name:=====>\\n\", visual_model_name[vm]+'_'+dl_textual_model_name[tm]+'_early')\n",
        "\n",
        "com_model.fit([train_image, train_pad_sequences],\n",
        "              train_data['label'],\n",
        "              validation_split=0.1,\n",
        "              epochs=20,\n",
        "              batch_size=32,\n",
        "              callbacks=callbacks_check(visual_model_name[vm]+'_'+dl_textual_model_name[tm]))\n"
      ],
      "metadata": {
        "id": "GwfpG7DoT161"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vm = 'Inception'\n",
        "tm = 'LSTM+CNN'\n",
        "print('Model name ===> ', vm + '_' + tm)\n",
        "model = load_model(models_path + vm + '_' + tm + \".h5\")\n",
        "pred = model.predict([test_image, test_pad_sequences])\n",
        "y_pred = np.argmax(pred, axis=1)\n",
        "print_metrices(test_data['label'], y_pred)\n"
      ],
      "metadata": {
        "id": "bjR3B85GgmLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv7v2HuQZoOz"
      },
      "source": [
        "## **Proposed Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Oi_uPijsYf"
      },
      "source": [
        "### **Inception TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsf2qpJxkO2N"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, Dense, Flatten, Conv1D,\n",
        "                                     MaxPooling1D, LSTM, Bidirectional, Embedding, BatchNormalization,\n",
        "                                     Dropout, concatenate)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDnEYM45jyJe"
      },
      "outputs": [],
      "source": [
        "def visual_models():\n",
        "    inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "    inception_model = inception\n",
        "    inception_model.trainable = False\n",
        "    inception_y = inception_model.output\n",
        "    inception_pool = GlobalAveragePooling2D()(inception_y)\n",
        "    inception_bn = BatchNormalization()(inception_pool)\n",
        "    inception_dense1 = Dense(256, activation='relu')(inception_bn)\n",
        "    inception_dropout1 = Dropout(0.5)(inception_dense1)\n",
        "    inception_dense2 = Dense(128, activation='relu')(inception_dropout1)\n",
        "    inception_dropout2 = Dropout(0.5)(inception_dense2)\n",
        "    inception_output = Dense(10, activation='relu')(inception_dropout2)\n",
        "    inception_img_model = Model(inputs=inception_model.input, outputs=inception_output)\n",
        "    image_models = [inception_img_model]\n",
        "    return image_models\n",
        "\n",
        "\n",
        "def textual_models():\n",
        "    lc_text_inputs = Input(shape=(max_len,))\n",
        "    lc_embedding_layer = Embedding(vocab_size, 64)(lc_text_inputs)\n",
        "    LSTM_Layer = Bidirectional(LSTM(32, return_sequences=True))(lc_embedding_layer)\n",
        "    lc_conv1 = Conv1D(64, 2, activation='relu')(LSTM_Layer)\n",
        "    lc_bn1 = BatchNormalization()(lc_conv1)\n",
        "    lc_pool1 = MaxPooling1D(2)(lc_bn1)\n",
        "    lc_conv2 = Conv1D(64, 2, activation='relu')(lc_pool1)\n",
        "    lc_bn2 = BatchNormalization()(lc_conv2)\n",
        "    lc_pool2 = MaxPooling1D(2)(lc_bn2)\n",
        "    lc_flat = Flatten()(lc_pool2)\n",
        "    lc_dense_layer_1 = Dense(128, activation='relu')(lc_flat)\n",
        "    lc_dropout1 = Dropout(0.5)(lc_dense_layer_1)\n",
        "    lc_dense_layer_2 = Dense(10, activation='relu')(lc_dropout1)\n",
        "    cnn_lstm_model = Model(inputs=lc_text_inputs, outputs=lc_dense_layer_2)\n",
        "    dl_textual_models = [cnn_lstm_model]\n",
        "    return dl_textual_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6RBWvKuoYRZ"
      },
      "outputs": [],
      "source": [
        "def visualize_model(model, model_name):\n",
        "    plot_model(model, to_file=f'{model_name}.png', show_shapes=True, show_layer_names=True)\n",
        "    img = mpimg.imread(f'{model_name}.png')\n",
        "    plt.figure(figsize=(100, 100))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngLyvOVRkFtd"
      },
      "outputs": [],
      "source": [
        "visual_model_name = ['InceptionV3']\n",
        "visual_models_lsit = visual_models()\n",
        "\n",
        "dl_textual_model_name = ['LSTM+CNN']\n",
        "dl_textual_models_lsit = textual_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFJGRvqxkaD8"
      },
      "outputs": [],
      "source": [
        "for vm, visual_model in enumerate(visual_models_lsit):\n",
        "    for tm, textual_model in enumerate(dl_textual_models_lsit):\n",
        "        con_layer = concatenate([visual_model.output, textual_model.output])\n",
        "        fusion_dense1 = Dense(256, activation='relu')(con_layer)\n",
        "        fusion_bn1 = BatchNormalization()(fusion_dense1)\n",
        "        fusion_dropout1 = Dropout(0.5)(fusion_bn1)\n",
        "        fusion_dense2 = Dense(128, activation='relu')(fusion_dropout1)\n",
        "        fusion_bn2 = BatchNormalization()(fusion_dense2)\n",
        "        fusion_dropout2 = Dropout(0.5)(fusion_bn2)\n",
        "        out = Dense(2, activation='softmax')(fusion_dropout2)\n",
        "        com_model = Model(inputs=[visual_model.input, textual_model.input], outputs=out)\n",
        "\n",
        "        com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "        model_name = visual_model_name[vm] + '_proposed' + dl_textual_model_name[tm] + '_early'\n",
        "        print(\"\\nModel Name:=====>\\n\", model_name)\n",
        "\n",
        "        # print(\"\\nModel Name:=====>\\n\", visual_model_name[vm] + '_proposed' + dl_textual_model_name[tm] + '_early')\n",
        "\n",
        "        visualize_model(com_model, model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_path = \"/content/drive/MyDrive/Research/Multimodal/Chinese\""
      ],
      "metadata": {
        "id": "L8sAuOPNhYN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPk5Bcbdo0cQ"
      },
      "outputs": [],
      "source": [
        "com_model.fit([train_image, train_pad_sequences],\n",
        "                      train_data['label'],\n",
        "                      validation_split=0.1,\n",
        "                      epochs=20,\n",
        "                      batch_size=32,\n",
        "                      callbacks=callbacks_check(visual_model_name[vm] + '_' + dl_textual_model_name[tm])\n",
        "                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s3C38pmlEaz"
      },
      "outputs": [],
      "source": [
        "for vm in visual_model_name:\n",
        "  for tm in dl_textual_model_name:\n",
        "    print('Model name ===> ',vm+'_proposed'+tm)\n",
        "    model = load_model(\"/content/drive/MyDrive/Research/Multimodal/ChineseInceptionV3_LSTM+CNN.h5\")\n",
        "    pred = model.predict([test_image,test_pad_sequences])\n",
        "    y_pred = np.argmax(pred,axis=1)\n",
        "    print_metrices(test_data['label'], y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insection- Late"
      ],
      "metadata": {
        "id": "K8yl0_Ij-NBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, Dense, Flatten, Conv1D,\n",
        "                                     MaxPooling1D, LSTM, Bidirectional, Embedding, BatchNormalization,\n",
        "                                     Dropout, concatenate)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "Zx09PlQn8-D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visual_models():\n",
        "    inception = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "    inception_model = inception\n",
        "    inception_model.trainable = False\n",
        "    inception_y = inception_model.output\n",
        "    inception_pool = GlobalAveragePooling2D()(inception_y)\n",
        "    inception_bn = BatchNormalization()(inception_pool)\n",
        "    inception_dense1 = Dense(256, activation='relu')(inception_bn)\n",
        "    inception_dropout1 = Dropout(0.5)(inception_dense1)\n",
        "    inception_dense2 = Dense(128, activation='relu')(inception_dropout1)\n",
        "    inception_dropout2 = Dropout(0.5)(inception_dense2)\n",
        "    inception_output = Dense(10, activation='relu')(inception_dropout2)\n",
        "    inception_img_model = Model(inputs=inception_model.input, outputs=inception_output)\n",
        "    image_models = [inception_img_model]\n",
        "    return image_models"
      ],
      "metadata": {
        "id": "EW4myOIO-yKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def textual_models():\n",
        "    lc_text_inputs = Input(shape=(max_len,))\n",
        "    lc_embedding_layer = Embedding(vocab_size, 64)(lc_text_inputs)\n",
        "    LSTM_Layer = Bidirectional(LSTM(32, return_sequences=True))(lc_embedding_layer)\n",
        "    lc_conv1 = Conv1D(64, 2, activation='relu')(LSTM_Layer)\n",
        "    lc_bn1 = BatchNormalization()(lc_conv1)\n",
        "    lc_pool1 = MaxPooling1D(2)(lc_bn1)\n",
        "    lc_conv2 = Conv1D(64, 2, activation='relu')(lc_pool1)\n",
        "    lc_bn2 = BatchNormalization()(lc_conv2)\n",
        "    lc_pool2 = MaxPooling1D(2)(lc_bn2)\n",
        "    lc_flat = Flatten()(lc_pool2)\n",
        "    lc_dense_layer_1 = Dense(128, activation='relu')(lc_flat)\n",
        "    lc_dropout1 = Dropout(0.5)(lc_dense_layer_1)\n",
        "    lc_dense_layer_2 = Dense(10, activation='relu')(lc_dropout1)\n",
        "    cnn_lstm_model = Model(inputs=lc_text_inputs, outputs=lc_dense_layer_2)\n",
        "    dl_textual_models = [cnn_lstm_model]\n",
        "    return dl_textual_models"
      ],
      "metadata": {
        "id": "4Y1xhldc-3M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visual_model_name = ['InceptionV3']\n",
        "visual_models_lsit = visual_models()\n",
        "\n",
        "dl_textual_model_name = ['LSTM+CNN']\n",
        "dl_textual_models_lsit = textual_models()"
      ],
      "metadata": {
        "id": "t4JJ0b-O-49c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for tm,textual_model in enumerate(dl_textual_models_lsit):\n",
        "  # Concatenating the output of 2 classifiers\n",
        "  # Reshape or flatten the output of one or both models to make them compatible for concatenation\n",
        "  visual_output = keras.layers.Flatten()(visual_models_lsit[0].output) # Flatten the visual model output\n",
        "  con_layer = keras.layers.concatenate([visual_output, textual_model.output])\n",
        "  # Provide a unique name for this Dense layer using tm in the name\n",
        "  final_dense = Dense(4, activation=\"relu\", name=f\"final_dense_{tm}\")(con_layer)\n",
        "  #dropout = Dropout(0.1)(final_dense)\n",
        "  # Provide a unique name for the output layer using tm in the name\n",
        "  out = Dense(2,activation='softmax', name=f\"output_layer_{tm}\")(final_dense)\n",
        "  com_model = Model(inputs = [visual_models_lsit[0].input, textual_model.input], outputs=out)\n",
        "\n",
        "  com_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics = [\"accuracy\"])\n",
        "\n",
        "\n",
        "  print(\"\\nModel Name:=====>\\n\",visual_model_name[0]+'_'+dl_textual_model_name[tm]+'proposed_late')\n",
        "\n",
        "  com_model.fit([train_image,train_pad_sequences],\n",
        "                      train_data['label'],\n",
        "                      validation_split = 0.1,\n",
        "                      epochs=20,\n",
        "                      batch_size=32,\n",
        "                      callbacks = callbacks_check(visual_model_name[0]+'_'+dl_textual_model_name[tm]+'proposed_late')\n",
        "            )"
      ],
      "metadata": {
        "id": "-QAzIkMY_Got"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for vm in visual_model_name:\n",
        "  for tm in dl_textual_model_name:\n",
        "    print('Model name ===> ',vm+'proposed_late'+tm)\n",
        "    model = load_model(models_path+ vm+'_'+tm+'proposed_late'+\".h5\")\n",
        "    pred = model.predict([test_image,test_pad_sequences])\n",
        "    y_pred = np.argmax(pred,axis=1)\n",
        "    print_metrices(test_data['label'], y_pred)"
      ],
      "metadata": {
        "id": "kZA3Y2Mo_JtF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yZkBKe2aqIeg",
        "QfvrhlSQqPgB",
        "MeafZsTmqafe",
        "PuDPgBhAqu_-",
        "ETmEOrpgroKH",
        "eQt5dIyerzBG",
        "9PsY6xzUDdWH",
        "r0H-UvuCDksW",
        "wB9ajAKDDpa9",
        "qe-AgXvaUlZQ"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}